{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing with DeepLab : https://github.com/DrSleep/tensorflow-deeplab-resnet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps to follow:\n",
    "\n",
    "In order to apply the same scripts using your own dataset, you would need to follow the next steps:\n",
    "\n",
    "0. Make sure that your segmentation masks are in the same format as the ones in the DeepLab setup (i.e., without a colour map). This means that if your segmentation masks are RGB images, you would need to convert each 3-D RGB vector into a 1-D label. For example, take a look [here](https://gist.github.com/DrSleep/4bce37254c5900545e6b65f6a0858b9c);\n",
    "1. Create a file with instances of your dataset in the same format as in files [here](https://github.com/DrSleep/tensorflow-deeplab-resnet/tree/master/dataset);\n",
    "2. Change the flags `data-dir` and `data-list` accordingly in thehttps://gist.github.com/DrSleep/4bce37254c5900545e6b65f6a0858b9c); script file that you will be using (e.g., `python train.py --data-dir /my/data/dir --data-list /my/data/list`);\n",
    "3. Change the `IMG_MEAN` vector accordingly in the script file that you will be using;\n",
    "4. For visualisation purposes, you will also need to change the colour map [here](https://github.com/DrSleep/tensorflow-deeplab-resnet/blob/master/deeplab_resnet/utils.py);\n",
    "5. Change the flags `num-classes` and `ignore-label` accordingly in the script that you will be using (e.g., `python train.py --ignore-label 255 --num-classes 21`).\n",
    "6. If restoring weights from the `PASCAL` models for your dataset with a different number of classes, you will also need to pass the `--not-restore-last` flag, which will prevent the last layers of size <code>21</code> from being restored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0-  Make sure that your segmentation masks are in the same format as the ones in the DeepLab setup (i.e., without a colour map)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_from_color_segmentation(arr_3d):\n",
    "    rr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
    "    class_grass = np.all(arr_3d == np.array((0,0,0)).reshape(1, 1, 3), axis=2)\n",
    "    class_burnt = np.all(arr_3d == np.array((240,0,0)).reshape(1, 1, 3), axis=2)\n",
    "    rr_2d[class_grass] = 255\n",
    "    rr_2d[class_burnt] = 0\n",
    "    return rr_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = glob.glob(\"dataset/segmented/*.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(label).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print(label)\n",
    "    label_arr = np.array(Image.open(label))\n",
    "    label_tf = Image.fromarray(convert_from_color_segmentation(label_arr))\n",
    "    label_tf.save(label.replace(\"segmented\",\"segmented_tf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Create a file with instances of your dataset in the same format as in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tf = glob.glob(\"/Users/Marcelpv96/Dropbox/UNI/LiquidLGalaxy/GSOC-2019-Dronecoria/dataset/segmented_tf/*.png\")\n",
    "images = glob.glob(\"/Users/Marcelpv96/Dropbox/UNI/LiquidLGalaxy/GSOC-2019-Dronecoria/dataset/burnt/*.png\")\n",
    "labels_tf.sort()\n",
    "images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = round(len(images)*0.7)\n",
    "validation_size = round(len(images)*0.1)\n",
    "test_size = round(len(images)*0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(file_name, size):\n",
    "    data_set = \"\"\n",
    "    for i in range(size[0], size[1]):\n",
    "        image = images[i]\n",
    "        label = labels_tf[i]\n",
    "        data_set += \"\"\"%s %s\n",
    "\"\"\" %((image, label))\n",
    "    with open(file_name, 'w') as data_set_file:\n",
    "        data_set_file.write(data_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_dataset(file_name, size):\n",
    "    data_set = \"\"\n",
    "    for i in range(size[0], size[1]-1):\n",
    "        image = images[i]\n",
    "        label = labels_tf[i]\n",
    "        data_set += \"\"\"%s\n",
    "\"\"\" %((label.split('/')[-1].replace(\".png\", \"\")))\n",
    "    with open(file_name, 'w') as data_set_file:\n",
    "        data_set_file.write(data_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_test_dataset('train.txt', (0, train_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_test_dataset('trainval.txt', (train_size, train_size+validation_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_test_dataset('val.txt', (train_size+validation_size, train_size+validation_size+test_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking output of my DeepLab NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['research/deeplab/burnt_forest/vis/segmentation_results/000011_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000005_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000024_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000030_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000002_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000017_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000018_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000008_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000029_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000010_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000005_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000022_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000036_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000004_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000011_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000019_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000017_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000003_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000016_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000003_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000041_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000004_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000014_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000001_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000010_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000031_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000009_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000025_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000006_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000013_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000009_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000028_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000037_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000023_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000002_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000012_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000007_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000016_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000040_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000008_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000000_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000015_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000026_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000032_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000029_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000013_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000034_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000021_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000007_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000026_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000033_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000042_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000032_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000027_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000015_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000001_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000043_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000020_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000034_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000020_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000035_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000018_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000044_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000043_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000028_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000039_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000033_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000022_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000037_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000027_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000006_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000012_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000041_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000044_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000030_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000025_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000038_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000039_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000000_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000014_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000035_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000040_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000021_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000024_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000031_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000019_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000042_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000038_image.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000036_prediction.png',\n",
       " 'research/deeplab/burnt_forest/vis/segmentation_results/000023_prediction.png']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('research/deeplab/burnt_forest/vis/segmentation_results/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_pred = np.array(Image.open(\"research/deeplab/burnt_forest/vis/segmentation_results/000011_prediction.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=948x812 at 0x1186829E8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
